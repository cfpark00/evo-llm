# ES Evolution Experiment Configuration

# Output configuration
output_dir: "data/es_countdown_v1"
seed: 42

# Task configuration
task:
  name: "countdown"
  train_data: "data/tasks/countdown/countdown.json"  # Will be split 80/20 at runtime

# Model configuration
model:
  name: "Qwen/Qwen2.5-7B-Instruct"

# LoRA configuration
lora:
  rank: 1
  alpha: 2
  target_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # Layers 0-9
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# ES hyperparameters
es:
  num_generations: 1000
  population_size: 30
  learning_rate: 0.01
  init_scale: 4.0      # Multiplier for Gen0 initialization (applied to per-layer base noise)
  perturb_scale: 1.0   # Multiplier for Gen1+ perturbations (applied to per-layer base noise)

# Evaluation configuration
evaluation:
  max_tokens: 1024  # Longer for countdown task
  temperature: 0.0  # Greedy decoding
